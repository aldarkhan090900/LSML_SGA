{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDFS Homework\n",
    "\n",
    "## Problem\n",
    "\n",
    "There is the log of online store's transactions in several files in json format located along the path /data/transactions/\n",
    "on the cluster in hdfs.\n",
    "\n",
    "File names are `site-transactions-01.json, ..., site-transactions-08.json`.\n",
    "\n",
    "The file structure is as follows:\n",
    "```json\n",
    "{\n",
    "    \"transactions\":\n",
    "    [\n",
    "        {\n",
    "            \"commitTimestamp\": \"2016-03-29 10:28:31\",\n",
    "            \"customerId\": 24,\n",
    "            \"trackId\": 838680843675,\n",
    "            \"goods\": \n",
    "            [\n",
    "                {\n",
    "                    \"amount\": 1, \n",
    "                    \"pricePerUnit\": 811.45, \n",
    "                    \"vendorCode\": \"44\"\n",
    "                },\n",
    "                {\n",
    "                    \"amount\": 1, \n",
    "                    \"pricePerUnit\": 365.86, \n",
    "                    \"vendorCode\": \"60\"\n",
    "                },\n",
    "                ...\n",
    "            ]\n",
    "        },\n",
    "        ...\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "You have to calculate how much the customer with `customerId=42` spent in total on the product with `vendorCode=\"104\"`.\n",
    "\n",
    "## Output\n",
    "\n",
    "Send the resulting number (i.e. 123) as JSON with following structure:\n",
    "```json\n",
    "{\n",
    "    \"q1\": 123\n",
    "}\n",
    "```\n",
    "\n",
    "Use /w6/t1 for sumbission.\n",
    "\n",
    "### Comment\n",
    "It is guaranteed that the size of one file does not exceed the size of one hdfs block.\n",
    "\n",
    "The correctness of the transaction log file is also guaranteed.\n",
    "\n",
    "It is assumed that an item with the same `vendorCode` may appear several times in the list of items of the same transaction.\n",
    "\n",
    "Try to solve the problem using the HDFS Python API.\n",
    "\n",
    "Before getting started, you need to set up your environment.\n",
    "You need to create the file `~/.hdfscli.cfg` containing the following:\n",
    "```\n",
    "[global]\n",
    "default.alias = default\n",
    "\n",
    "[default.alias]\n",
    "url = http://localhost:50070/\n",
    "user = <YOUR_USER_LOGIN>\n",
    "```\n",
    "\n",
    "Now you can use the Python API.\n",
    "```\n",
    ">>> from hdfs import Config\n",
    ">>> client = Config().get_client()\n",
    ">>> client.list('/data')\n",
    "['access_logs', ..., 'lsml' ... ]\n",
    "```\n",
    "\n",
    "More examples:\n",
    "https://hdfscli.readthedocs.io/en/latest/quickstart.html#reading-and-writing-files\n",
    "read, write, downloading and uploading to local filesystem\n",
    "\n",
    "Getting file's status:\n",
    "```\n",
    ">>> client.status('/data/wiki')\n",
    "{'accessTime': 0, 'length': 0, ...}\n",
    "```\n",
    "\n",
    "More libraries for Python: `hadoopy, pydoop, dumbo, mrjob`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE IS YOUR SOLUTION\n",
    "# DO NOT FORGET TO COPY FILE FOR SOLUTION, DO NOT SHARE YOUR CODE"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "week-4-spark-homework"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
